#!/usr/bin/env python3
"""
Joan CLI - Global monitoring for joan-agents
=============================================

Usage:
    joan status              # Global view of all running agents
    joan status <project>    # Detailed view of specific project
    joan logs <project>      # Tail logs for specific project
"""

import sys
import os
import re
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict
import time
import argparse
import json

try:
    from rich.console import Console
    from rich.live import Live
    from rich.table import Table
    from rich.panel import Panel
    from rich.layout import Layout
    from rich.text import Text
    from rich import box
except ImportError:
    print("Error: Rich library not installed")
    print("Install with: python3 -m pip install --user --break-system-packages rich")
    sys.exit(1)


class JoanMonitor:
    """Global monitor for all running joan-agents instances."""

    PIPELINE_STAGES = ["BA", "Architect", "Dev", "Reviewer", "Ops"]

    def __init__(self):
        self.console = Console()
        self.instances = {}  # project_name -> instance_info
        self.blink_state = False  # For animation

    def discover_instances(self):
        """Find all running joan-agents processes (webhook receiver or legacy scheduler)."""
        self.instances = {}

        try:
            # Find all running joan-agents processes
            # Supports: webhook-server.py (Python), webhook-receiver.sh (bash wrapper), joan-scheduler.sh (legacy)
            result = subprocess.run(
                ["ps", "aux"],
                capture_output=True,
                text=True,
                check=True
            )

            for line in result.stdout.splitlines():
                # Support Python webhook server, bash wrapper, and legacy scheduler
                is_python_webhook = "webhook-server.py" in line and "grep" not in line
                is_bash_webhook = "webhook-receiver.sh" in line and "grep" not in line
                is_scheduler = "joan-scheduler.sh" in line and "grep" not in line

                is_webhook = is_python_webhook or is_bash_webhook

                if is_webhook or is_scheduler:
                    # Extract PID and project directory from command line
                    pid_match = re.match(r'\S+\s+(\d+)', line)
                    # Match --project-dir argument (used by all webhook variants)
                    if is_webhook:
                        path_match = re.search(r'--project-dir[=\s]+([^\s]+)', line)
                    else:
                        path_match = re.search(r'joan-scheduler\.sh\s+([^\s]+)', line)

                    if path_match and pid_match:
                        raw_path = path_match.group(1)
                        pid = pid_match.group(1)

                        # If path is relative (. or ./something or doesn't start with /),
                        # resolve it from the process's actual working directory
                        if not raw_path.startswith('/'):
                            try:
                                # Get the process's working directory via lsof
                                lsof_result = subprocess.run(
                                    ["lsof", "-p", pid],
                                    capture_output=True,
                                    text=True,
                                    timeout=5
                                )
                                for lsof_line in lsof_result.stdout.splitlines():
                                    if '\tcwd\t' in lsof_line or ' cwd ' in lsof_line:
                                        # Extract the directory path (last field)
                                        parts = lsof_line.split()
                                        if len(parts) >= 9:
                                            process_cwd = parts[-1]
                                            project_dir = Path(process_cwd) / raw_path
                                            project_dir = project_dir.resolve()
                                            break
                                else:
                                    # Fallback if lsof doesn't give cwd
                                    project_dir = Path(raw_path).resolve()
                            except (subprocess.TimeoutExpired, Exception):
                                project_dir = Path(raw_path).resolve()
                        else:
                            project_dir = Path(raw_path).resolve()

                        if project_dir.exists():
                            self._add_instance(project_dir, line, is_webhook=is_webhook)

        except subprocess.CalledProcessError:
            pass

    def _add_instance(self, project_dir: Path, ps_line: str, is_webhook: bool = False):
        """Add a discovered instance to the tracking dict."""
        config_file = project_dir / ".joan-agents.json"
        if not config_file.exists():
            return

        # Read config
        import json
        try:
            with open(config_file) as f:
                config = json.load(f)
        except:
            return

        project_name = config.get("projectName", project_dir.name)

        # Use appropriate log file based on mode
        if is_webhook:
            log_file = project_dir / ".claude/logs/webhook-receiver.log"
        else:
            log_file = project_dir / ".claude/logs/scheduler.log"

        # Parse log for stats (different parser for webhook mode)
        if is_webhook:
            stats = self._parse_webhook_log_stats(log_file) if log_file.exists() else {}
        else:
            stats = self._parse_log_stats(log_file) if log_file.exists() else {}

        # Parse metrics for Doctor/rework tracking
        metrics_file = project_dir / ".claude/logs/agent-metrics.jsonl"
        metrics = self._parse_metrics(metrics_file) if metrics_file.exists() else {}

        # Parse worker activity log
        worker_log = project_dir / ".claude/logs/worker-activity.log"
        worker_activity = self._parse_worker_activity(worker_log) if worker_log.exists() else {}

        # Extract PID from ps line
        pid_match = re.match(r'\S+\s+(\d+)', ps_line)
        pid = pid_match.group(1) if pid_match else "unknown"

        self.instances[project_name] = {
            "project_dir": project_dir,
            "config": config,
            "log_file": log_file,
            "metrics_file": metrics_file,
            "worker_log": worker_log,
            "pid": pid,
            "stats": stats,
            "metrics": metrics,
            "worker_activity": worker_activity,
            "mode": "webhook" if is_webhook else "polling"
        }

    def _parse_log_stats(self, log_file: Path):
        """Parse log file to extract runtime statistics."""
        if not log_file.exists():
            return {}

        stats = {
            "cycle": 0,
            "idle_count": 0,
            "max_idle": 12,
            "last_poll": None,
            "started_at": None,
            "active_workers": [],
            "tasks_completed": 0,
            "workers_dispatched": 0,
            "recent_events": [],
            "pipeline_state": {},  # Track tasks in each workflow stage
            "coordinator_in_progress": False,  # True if coordinator is currently running
            "coordinator_started_at": None     # When current coordinator started
        }

        try:
            with open(log_file, 'r') as f:
                lines = f.readlines()

            # Find start time
            if lines:
                first_line = lines[0]
                ts_match = re.match(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', first_line)
                if ts_match:
                    stats["started_at"] = datetime.strptime(ts_match.group(1), '%Y-%m-%d %H:%M:%S')

            # Track which workers have completed (to avoid showing them as active)
            completed_workers = set()

            # Check if coordinator is currently running (started but not completed)
            # Parse forward through last 100 lines to find most recent start/complete pair
            coordinator_last_started = None
            coordinator_last_completed = None
            for line in lines[-100:]:
                ts_match = re.match(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                if ts_match:
                    line_ts = datetime.strptime(ts_match.group(1), '%Y-%m-%d %H:%M:%S')
                    if "Starting coordinator" in line:
                        coordinator_last_started = line_ts
                    elif "Coordinator completed" in line:
                        coordinator_last_completed = line_ts

            # If started more recently than completed, coordinator is in progress
            if coordinator_last_started:
                if coordinator_last_completed is None or coordinator_last_started > coordinator_last_completed:
                    stats["coordinator_in_progress"] = True
                    stats["coordinator_started_at"] = coordinator_last_started

            # Parse from end for most recent info
            for line in reversed(lines[-200:]):  # Last 200 lines
                # Extract timestamp
                ts_match = re.match(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                timestamp = None
                if ts_match:
                    timestamp = datetime.strptime(ts_match.group(1), '%Y-%m-%d %H:%M:%S')

                # Cycle number
                if "Cycle" in line and "starting" in line and stats["cycle"] == 0:
                    match = re.search(r'Cycle (\d+)', line)
                    if match:
                        stats["cycle"] = int(match.group(1))
                        if timestamp:
                            stats["last_poll"] = timestamp

                # Idle count
                if "idle count:" in line:
                    match = re.search(r'idle count: (\d+)/(\d+)', line)
                    if match:
                        stats["idle_count"] = int(match.group(1))
                        stats["max_idle"] = int(match.group(2))

                # Active workers - detect from dispatch events
                if "**" in line and "worker" in line.lower():
                    match = re.search(r'\*\*(\w+) worker (dispatched|claimed) for [\'"]([^\'"]+)[\'"]\*\*', line)
                    if match:
                        worker_type = match.group(1)
                        task_name = match.group(3)
                        # Skip if this worker has already completed (we're parsing in reverse)
                        if worker_type not in completed_workers and worker_type not in [w["type"] for w in stats["active_workers"]]:
                            stats["active_workers"].append({
                                "type": worker_type,
                                "task": task_name,
                                "started_at": timestamp or datetime.now()
                            })

                # Also detect from "still running" diagnostic messages
                # Pattern: "dev worker that claimed task #7 is presumably still running"
                if "still running" in line.lower() or "presumably still running" in line.lower():
                    match = re.search(r'(\w+) worker (?:that )?claimed', line, re.IGNORECASE)
                    task_match = re.search(r'task #?(\d+)|[\'"]([^\'"]+)[\'"]', line)
                    if match:
                        worker_type = match.group(1).capitalize()
                        if worker_type == "Dev":
                            worker_type = "Dev"
                        task_name = ""
                        if task_match:
                            task_name = task_match.group(1) or task_match.group(2) or ""
                            if task_match.group(1):
                                task_name = f"Task #{task_name}"
                        if worker_type not in completed_workers and worker_type not in [w["type"] for w in stats["active_workers"]]:
                            stats["active_workers"].append({
                                "type": worker_type,
                                "task": task_name,
                                "started_at": timestamp or datetime.now()
                            })

                # Detect from "actively being implemented" or "is implementing" messages
                if "actively being implemented" in line.lower() or "is implementing" in line.lower():
                    match = re.search(r'by (Dev|BA|Architect|Reviewer|Ops)[-\s]?(\d)?', line, re.IGNORECASE)
                    task_match = re.search(r'[\'"]([^\'"]+)[\'"]|Task #?(\d+)', line)
                    if match:
                        worker_type = match.group(1).capitalize()
                        task_name = ""
                        if task_match:
                            task_name = task_match.group(1) or f"Task #{task_match.group(2)}" or ""
                        if worker_type not in completed_workers and worker_type not in [w["type"] for w in stats["active_workers"]]:
                            stats["active_workers"].append({
                                "type": worker_type,
                                "task": task_name,
                                "started_at": timestamp or datetime.now()
                            })

                # Detect from "is claimed by Dev-N" pattern
                # Pattern: Task #7 "STRETCH: Multiple Game Modes" is claimed by Dev-1
                if "is claimed by" in line.lower():
                    match = re.search(r'is claimed by (Dev|BA|Architect|Reviewer|Ops)[-\s]?(\d)?', line, re.IGNORECASE)
                    task_match = re.search(r'Task #?(\d+)\s*[\'"]([^\'"]+)[\'"]|[\'"]([^\'"]+)[\'"]', line)
                    if match:
                        worker_type = match.group(1).capitalize()
                        task_name = ""
                        if task_match:
                            if task_match.group(1) and task_match.group(2):
                                task_name = f"#{task_match.group(1)} {task_match.group(2)}"
                            elif task_match.group(3):
                                task_name = task_match.group(3)
                        if worker_type not in completed_workers and worker_type not in [w["type"] for w in stats["active_workers"]]:
                            stats["active_workers"].append({
                                "type": worker_type,
                                "task": task_name,
                                "started_at": timestamp or datetime.now()
                            })

                # Completed workers - track so we don't show them as active
                if "**" in line and "completed" in line:
                    match = re.search(r'\*\*(\w+) worker completed', line)
                    if match:
                        stats["tasks_completed"] += 1
                        worker_type = match.group(1)
                        completed_workers.add(worker_type)
                        # Also remove if already in active list
                        stats["active_workers"] = [
                            w for w in stats["active_workers"]
                            if w["type"] != worker_type
                        ]

                # Dispatched count - handle multiple log formats:
                # - "Poll complete: dispatched 10 workers (all BA)"
                # - "Dispatched: 1 worker (Architect for task #1)"
                # - "Dispatched **N** worker" (legacy markdown format)
                if "dispatched" in line.lower():
                    # Try various patterns
                    match = re.search(r'dispatched[:\s]+(\d+)\s+worker', line, re.IGNORECASE)
                    if not match:
                        match = re.search(r'dispatched\s+\*\*(\d+)\*\*\s+worker', line, re.IGNORECASE)
                    if match:
                        count = int(match.group(1))
                        stats["workers_dispatched"] += count

                # Pipeline state from coordinator summary
                # Look for patterns like "X in active development", "X tasks in Review"
                if "in active development" in line.lower() or "in development" in line.lower():
                    match = re.search(r'(\d+)\s+(?:tasks?\s+)?in\s+(?:active\s+)?development', line, re.IGNORECASE)
                    if match and int(match.group(1)) > 0:
                        stats["pipeline_state"]["Dev"] = int(match.group(1))

                if "in review" in line.lower():
                    match = re.search(r'(\d+)\s+(?:tasks?\s+)?in\s+review', line, re.IGNORECASE)
                    if match and int(match.group(1)) > 0:
                        stats["pipeline_state"]["Reviewer"] = int(match.group(1))

                if "in analyse" in line.lower() or "in analysis" in line.lower():
                    match = re.search(r'(\d+)\s+(?:tasks?\s+)?in\s+analy[sz]e?', line, re.IGNORECASE)
                    if match and int(match.group(1)) > 0:
                        stats["pipeline_state"]["Architect"] = int(match.group(1))

                if "ready for ba" in line.lower() or "in to do" in line.lower():
                    match = re.search(r'(\d+)\s+(?:tasks?\s+)?(?:ready\s+for\s+ba|in\s+to\s+do)', line, re.IGNORECASE)
                    if match and int(match.group(1)) > 0:
                        stats["pipeline_state"]["BA"] = int(match.group(1))

                if "ready to deploy" in line.lower() or "in deploy" in line.lower():
                    match = re.search(r'(\d+)\s+(?:tasks?\s+)?(?:ready\s+to\s+deploy|in\s+deploy)', line, re.IGNORECASE)
                    if match and int(match.group(1)) > 0:
                        stats["pipeline_state"]["Ops"] = int(match.group(1))

        except Exception as e:
            pass

        return stats

    def _parse_webhook_log_stats(self, log_file: Path):
        """Parse webhook receiver log file to extract runtime statistics."""
        if not log_file.exists():
            return {}

        stats = {
            "mode": "webhook",
            "started_at": None,
            "last_event": None,
            "events_received": 0,
            "handlers_dispatched": 0,
            "active_workers": [],
            "tasks_completed": 0,
            "recent_events": [],
            "handlers_by_type": {},  # Count by handler type
        }

        try:
            with open(log_file, 'r') as f:
                lines = f.readlines()

            # Find start time from first line
            if lines:
                first_line = lines[0]
                # Format: [2026-01-23T14:30:00] [INFO] Starting webhook receiver
                # or: [2026-01-23T14:30:00-05:00] Starting webhook receiver
                ts_match = re.match(r'\[([^\]]+)\]', first_line)
                if ts_match:
                    try:
                        ts_str = ts_match.group(1)
                        # Handle various timezone formats
                        ts_str = ts_str.replace('+00:00', '').replace('-05:00', '').replace('-04:00', '')
                        stats["started_at"] = datetime.fromisoformat(ts_str)
                    except:
                        pass

            # Track active handlers (dispatched but not yet completed)
            active_handlers = {}  # pid -> {type, task, started_at}

            # Parse lines for events
            for line in lines:
                # Extract timestamp - handle format with [LEVEL] tag
                # Format: [2026-01-23T14:30:00] [INFO] message
                ts_match = re.match(r'\[([^\]]+)\]', line)
                timestamp = None
                if ts_match:
                    try:
                        ts_str = ts_match.group(1)
                        ts_str = ts_str.replace('+00:00', '').replace('-05:00', '').replace('-04:00', '')
                        timestamp = datetime.fromisoformat(ts_str)
                    except:
                        pass

                # Count received events (support both old and new format)
                if "Received event:" in line or "Webhook received:" in line:
                    stats["events_received"] += 1
                    if timestamp:
                        stats["last_event"] = timestamp

                # Count and track dispatched handlers
                if "Dispatching:" in line:
                    stats["handlers_dispatched"] += 1
                    # Extract handler type: "Dispatching: handle-architect --task=abc123"
                    match = re.search(r'Dispatching: (handle-\w+)', line)
                    if match:
                        handler_type = match.group(1).replace("handle-", "").capitalize()
                        stats["handlers_by_type"][handler_type] = stats["handlers_by_type"].get(handler_type, 0) + 1

                        # Extract task ID
                        task_match = re.search(r'--task=([^\s]+)', line)
                        task_id = task_match.group(1) if task_match else "unknown"

                # Track handler completion via PID
                if "Handler dispatched (PID:" in line:
                    pid_match = re.search(r'PID: (\d+)', line)
                    if pid_match:
                        pid = pid_match.group(1)
                        # This handler is now running
                        # We'd need to check if PID is still running to know if active

                # Track completions from worker activity log patterns in webhook log
                if "completed" in line.lower() and ("worker" in line.lower() or "handler" in line.lower()):
                    stats["tasks_completed"] += 1

                # Also count from CATCHUP messages
                if "Single-pass dispatch complete" in line or "CATCHUP" in line:
                    if timestamp:
                        stats["last_event"] = timestamp

                # Build recent events list
                if any(kw in line for kw in ["Dispatching:", "Received event:", "Webhook received:",
                                              "completed", "error", "CATCHUP", "Handler"]):
                    if timestamp:
                        stats["recent_events"].append({
                            "timestamp": timestamp,
                            "line": line.strip()
                        })

            # Keep only last 20 recent events
            stats["recent_events"] = stats["recent_events"][-20:]

        except Exception as e:
            pass

        return stats

    def _parse_metrics(self, metrics_file: Path):
        """Parse agent-metrics.jsonl for Doctor invocations and reworks."""
        if not metrics_file.exists():
            return {}

        metrics = {
            "doctor_invocations": 0,
            "doctor_fixes": 0,
            "reworks": 0,
            "completions": 0,
            "failures": 0,
            "recent_doctor_events": [],  # Last 5 Doctor invocations
            "recent_reworks": [],        # Last 5 rework events
            "workflow_step_issues": defaultdict(int),  # Count by workflow step
        }

        try:
            with open(metrics_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        event = json.loads(line)
                        event_type = event.get("event")
                        timestamp_str = event.get("timestamp", "")

                        # Parse timestamp
                        timestamp = None
                        if timestamp_str:
                            try:
                                timestamp = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
                            except:
                                pass

                        if event_type == "doctor_invocation":
                            metrics["doctor_invocations"] += 1
                            metrics["doctor_fixes"] += event.get("fixes_applied", 0)

                            # Track workflow steps where issues occurred
                            for issue in event.get("issues", []):
                                step = issue.get("workflow_step", "Unknown")
                                metrics["workflow_step_issues"][step] += 1

                            # Keep recent events
                            metrics["recent_doctor_events"].append({
                                "timestamp": timestamp,
                                "trigger": event.get("trigger", "unknown"),
                                "issues_found": event.get("issues_found", 0),
                                "fixes_applied": event.get("fixes_applied", 0),
                                "mode": event.get("mode", "fix"),
                                "issues": event.get("issues", [])[:3]  # Keep up to 3 issues for display
                            })
                            # Keep only last 5
                            metrics["recent_doctor_events"] = metrics["recent_doctor_events"][-5:]

                        elif event_type == "rework_requested":
                            metrics["reworks"] += 1
                            metrics["recent_reworks"].append({
                                "timestamp": timestamp,
                                "task_title": event.get("task_title", "Unknown"),
                                "workflow_step": event.get("workflow_step", "Reviewâ†’Development"),
                                "reason": event.get("reason", "")[:100]  # Truncate reason
                            })
                            # Keep only last 5
                            metrics["recent_reworks"] = metrics["recent_reworks"][-5:]

                        elif event_type == "task_completed":
                            metrics["completions"] += 1

                        elif event_type == "implementation_failed":
                            metrics["failures"] += 1

                    except json.JSONDecodeError:
                        continue

        except Exception as e:
            pass

        return metrics

    def _parse_worker_activity(self, worker_log: Path):
        """Parse worker-activity.log for real-time worker status."""
        if not worker_log.exists():
            return {}

        activity = {
            "current_worker": None,      # Currently active worker info
            "current_task": None,        # Task being worked on
            "current_status": None,      # START, PROGRESS, COMPLETE, FAIL
            "last_message": None,        # Last activity message
            "last_update": None,         # Timestamp of last update
            "recent_events": [],         # Last 10 events
        }

        try:
            with open(worker_log, 'r') as f:
                lines = f.readlines()

            # Parse last 50 lines for recent activity
            for line in lines[-50:]:
                line = line.strip()
                if not line:
                    continue

                # Pattern: [2026-01-23 11:07:15] [Dev] [START] task=#7 'Multiple Game Modes'
                match = re.match(
                    r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\] \[(\w+)\] \[(\w+)\] (.+)',
                    line
                )
                if match:
                    timestamp_str = match.group(1)
                    worker_type = match.group(2)
                    status = match.group(3)
                    message = match.group(4)

                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                    except:
                        timestamp = datetime.now()

                    event = {
                        "timestamp": timestamp,
                        "worker": worker_type,
                        "status": status,
                        "message": message
                    }

                    activity["recent_events"].append(event)

                    # Track current state
                    if status == "START":
                        activity["current_worker"] = worker_type
                        activity["current_status"] = "WORKING"
                        activity["current_task"] = message
                        activity["last_update"] = timestamp
                        activity["last_message"] = message
                    elif status == "PROGRESS":
                        activity["current_status"] = "WORKING"
                        activity["last_update"] = timestamp
                        activity["last_message"] = message
                    elif status in ("COMPLETE", "FAIL"):
                        activity["current_worker"] = None
                        activity["current_status"] = status
                        activity["current_task"] = None
                        activity["last_update"] = timestamp
                        activity["last_message"] = f"{worker_type}: {message}"

            # Keep only last 10 events
            activity["recent_events"] = activity["recent_events"][-10:]

        except Exception as e:
            pass

        return activity

    def _get_worker_progress_content(self, worker_log: Path, worker_type: str = None, max_lines: int = 15) -> Text:
        """Get formatted worker progress content for display when a worker is active.

        Shows a focused view of worker activity, filtering to the active worker type if specified.
        """
        text = Text()

        if not worker_log.exists():
            text.append("No worker activity log found\n", "dim")
            text.append(f"Expected: {worker_log}", "dim")
            return text

        try:
            with open(worker_log, 'r') as f:
                lines = f.readlines()

            # Parse and filter events
            events = []
            now = datetime.now()

            for line in lines[-100:]:  # Check last 100 lines
                line = line.strip()
                if not line:
                    continue

                # Pattern: [2026-01-23 11:07:15] [Dev] [START] task=#7 'Multiple Game Modes'
                match = re.match(
                    r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\] \[(\w+)\] \[(\w+)\] (.+)',
                    line
                )
                if match:
                    timestamp_str = match.group(1)
                    event_worker = match.group(2)
                    status = match.group(3)
                    message = match.group(4)

                    # Filter to specific worker type if requested
                    if worker_type and event_worker != worker_type:
                        continue

                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                    except:
                        timestamp = now

                    events.append({
                        "timestamp": timestamp,
                        "worker": event_worker,
                        "status": status,
                        "message": message
                    })

            # Take last N events
            recent_events = events[-max_lines:]

            if not recent_events:
                text.append("No recent worker activity", "dim")
                if worker_type:
                    text.append(f"\n(Filtering for {worker_type} worker)", "dim")
                return text

            # Format events with color coding
            for event in recent_events:
                elapsed = now - event["timestamp"]
                elapsed_str = self._format_duration(elapsed)

                # Status icons and colors
                status_config = {
                    "START": ("â–¶", "bold green"),
                    "PROGRESS": ("â—†", "cyan"),
                    "COMPLETE": ("âœ“", "bold green"),
                    "FAIL": ("âœ—", "bold red"),
                }
                icon, style = status_config.get(event["status"], ("â€¢", "white"))

                # Time column
                text.append(f"{elapsed_str:>8} ", "dim")

                # Status icon
                text.append(f"{icon} ", style)

                # Worker tag (only if not filtering)
                if not worker_type:
                    text.append(f"[{event['worker']:10}] ", "cyan")

                # Message - truncate if needed
                msg = event["message"]
                max_msg_len = 70 if worker_type else 55
                if len(msg) > max_msg_len:
                    msg = msg[:max_msg_len-3] + "..."
                text.append(f"{msg}\n", "white")

        except Exception as e:
            text.append(f"Error reading worker log: {e}", "red")

        return text

    def show_global_view(self, live_mode: bool = False):
        """Display global view of all running instances."""
        if live_mode:
            try:
                with Live(self._generate_global_layout(), refresh_per_second=2, console=self.console) as live:
                    while True:
                        self.discover_instances()
                        live.update(self._generate_global_layout())
                        time.sleep(0.5)
            except KeyboardInterrupt:
                self.console.print("\n[yellow]Stopped monitoring[/yellow]\n")
            return

        # Static view
        self.discover_instances()

        if not self.instances:
            self.console.print("\n[yellow]No running joan-agents instances found[/yellow]")
            self.console.print("\nStart agents with:")
            self.console.print("  [cyan]./scripts/webhook-receiver.sh --project-dir .[/cyan]  (webhook mode - recommended)")
            self.console.print("  [cyan]/agents:dispatch --loop[/cyan]  (polling mode - legacy)\n")
            return

        self.console.print()
        self.console.print(self._generate_global_table())
        self.console.print()
        self.console.print("[dim]Run [cyan]joan status <project> -f[/cyan] for live view[/dim]")
        self.console.print("[dim]Run [cyan]joan status -f[/cyan] for live global view[/dim]")
        self.console.print("[dim]Run [cyan]joan logs <project>[/cyan] to tail logs[/dim]\n")

    def _generate_global_table(self) -> Table:
        """Generate the global status table."""
        table = Table(
            title="Joan Agents - Global Status",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold cyan"
        )

        table.add_column("#", style="dim", width=3)
        table.add_column("Project", style="cyan", width=18)
        table.add_column("Mode", justify="center", width=7)
        table.add_column("Events", justify="right", width=7)  # Events for webhook, Cycle for polling
        table.add_column("Active", justify="center", width=6)
        table.add_column("Done", justify="right", width=5)
        table.add_column("ðŸ©º", justify="right", width=4)  # Doctor invocations
        table.add_column("â†©ï¸", justify="right", width=4)   # Reworks
        table.add_column("Runtime", justify="right", width=9)
        table.add_column("Status", width=20)

        now = datetime.now()
        for idx, (proj_name, info) in enumerate(sorted(self.instances.items()), 1):
            stats = info["stats"]
            metrics = info.get("metrics", {})
            mode = info.get("mode", "polling")

            # Format runtime
            if stats.get("started_at"):
                runtime = now - stats["started_at"]
                runtime_str = self._format_duration(runtime)
            else:
                runtime_str = "N/A"

            # Mode-specific display
            if mode == "webhook":
                mode_str = "[green]âš¡[/green]"  # Lightning bolt for webhook
                events_str = str(stats.get("events_received", 0))

                # Status for webhook mode
                active_count = len(stats.get("active_workers", []))
                if active_count > 0:
                    status = f"ðŸ”„ {active_count} worker{'s' if active_count > 1 else ''}"
                    status_style = "green"
                else:
                    last_event = stats.get("last_event")
                    if last_event:
                        elapsed = (now - last_event).total_seconds()
                        if elapsed < 60:
                            status = f"ðŸ“¡ Active ({int(elapsed)}s ago)"
                            status_style = "green"
                        elif elapsed < 300:
                            status = f"ðŸ“¡ Listening ({int(elapsed/60)}m)"
                            status_style = "cyan"
                        else:
                            status = f"ðŸ“¡ Idle ({int(elapsed/60)}m)"
                            status_style = "yellow"
                    else:
                        status = "ðŸ“¡ Listening"
                        status_style = "cyan"
            else:
                mode_str = "[dim]ðŸ”„[/dim]"  # Cycle for polling
                events_str = str(stats.get("cycle", 0))

                # Status for polling mode (legacy)
                active_count = len(stats.get("active_workers", []))
                if active_count > 0:
                    status = f"ðŸ”„ {active_count} worker{'s' if active_count > 1 else ''}"
                    status_style = "green"
                elif stats.get("coordinator_in_progress"):
                    started_at = stats.get("coordinator_started_at")
                    if started_at:
                        elapsed = (now - started_at).total_seconds()
                        elapsed_str = f"{int(elapsed)}s"
                        status = f"âš™ï¸ Working ({elapsed_str})"
                    else:
                        status = "âš™ï¸ Working"
                    status_style = "green"
                elif stats.get("idle_count", 0) > 0:
                    status = f"ðŸ’¤ Idle ({stats['idle_count']}/{stats.get('max_idle', 12)})"
                    status_style = "yellow"
                else:
                    status = "âœ“ Working"
                    status_style = "green"

            # Doctor/Rework counts with color coding
            doctor_count = metrics.get("doctor_invocations", 0)
            rework_count = metrics.get("reworks", 0)

            # Color code based on count (higher = more attention needed)
            doctor_style = "red" if doctor_count >= 5 else "yellow" if doctor_count >= 2 else "dim"
            rework_style = "red" if rework_count >= 5 else "yellow" if rework_count >= 2 else "dim"

            table.add_row(
                str(idx),
                proj_name[:16] + ".." if len(proj_name) > 16 else proj_name,
                mode_str,
                events_str,
                str(active_count),
                str(stats.get("tasks_completed", 0)),
                f"[{doctor_style}]{doctor_count}[/{doctor_style}]",
                f"[{rework_style}]{rework_count}[/{rework_style}]",
                runtime_str,
                f"[{status_style}]{status}[/{status_style}]"
            )

        return table

    def _generate_global_layout(self) -> Layout:
        """Generate Rich layout for live global view."""
        if not self.instances:
            return Panel(
                "[yellow]No running joan-agents instances found[/yellow]\n\n"
                "Start with:\n"
                "  [cyan]./scripts/webhook-receiver.sh --project-dir .[/cyan]  (webhook mode)\n"
                "  [cyan]/agents:dispatch --loop[/cyan]  (polling mode)",
                title="Joan Agents - Global Status"
            )

        layout = Layout()
        layout.split_column(
            Layout(name="header", size=3),
            Layout(name="table"),
            Layout(name="logs", size=12)
        )

        # Header with timestamp
        now = datetime.now()
        header_text = Text(
            f"Joan Agents - Global Status (Live)  {now.strftime('%H:%M:%S')}",
            style="bold cyan",
            justify="center"
        )
        layout["header"].update(Panel(header_text, border_style="cyan"))

        # Table
        layout["table"].update(self._generate_global_table())

        # Recent logs from all projects
        logs_text = self._get_combined_recent_logs()
        layout["logs"].update(
            Panel(logs_text, title="Recent Activity (All Projects)", border_style="blue")
        )

        return layout

    def _get_combined_recent_logs(self, lines: int = 8) -> Text:
        """Get recent log lines from all projects, interleaved by time."""
        all_logs = []

        for proj_name, info in self.instances.items():
            log_file = info["log_file"]
            if not log_file.exists():
                continue

            try:
                with open(log_file, 'r') as f:
                    recent_lines = f.readlines()[-20:]  # Get last 20 lines

                for line in recent_lines:
                    # Extract timestamp
                    ts_match = re.match(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                    if ts_match:
                        timestamp = datetime.strptime(ts_match.group(1), '%Y-%m-%d %H:%M:%S')
                        # Only include interesting events
                        if any(keyword in line for keyword in [
                            "worker", "Cycle", "dispatched", "completed",
                            "Idle", "Starting", "Shutdown"
                        ]):
                            all_logs.append({
                                'timestamp': timestamp,
                                'project': proj_name,
                                'line': line.strip()
                            })
            except:
                pass

        # Sort by timestamp (most recent last)
        all_logs.sort(key=lambda x: x['timestamp'])

        # Take last N entries
        recent = all_logs[-lines:]

        # Format as text
        text = Text()
        now = datetime.now()
        for entry in recent:
            elapsed = now - entry['timestamp']
            elapsed_str = self._format_duration(elapsed)

            # Extract message part (after [INFO])
            msg = entry['line']
            if "[INFO]" in msg:
                msg = msg.split("[INFO]", 1)[1].strip()

            # Color code by project
            proj_short = entry['project'][:12]
            text.append(f"{elapsed_str:>8} ago ", style="dim")
            text.append(f"[{proj_short:12}] ", style="cyan")
            text.append(msg[:60] + "\n", style="white")

        if not recent:
            text.append("No recent activity", style="dim")

        return text

    def show_project_view(self, project_name: str, follow: bool = False):
        """Display detailed view for a specific project."""
        self.discover_instances()

        # Find matching project (case-insensitive partial match)
        matches = [
            (name, info) for name, info in self.instances.items()
            if project_name.lower() in name.lower()
        ]

        if not matches:
            self.console.print(f"\n[red]No running instance found for '{project_name}'[/red]\n")
            return

        if len(matches) > 1:
            self.console.print(f"\n[yellow]Multiple matches found:[/yellow]")
            for name, _ in matches:
                self.console.print(f"  - {name}")
            self.console.print("\n[dim]Be more specific[/dim]\n")
            return

        proj_name, info = matches[0]

        if follow:
            # Live updating view
            self._show_live_project_view(proj_name, info)
        else:
            # Static snapshot
            self._show_static_project_view(proj_name, info)

    def _show_static_project_view(self, proj_name: str, info: dict):
        """Show a static snapshot of project details."""
        stats = info["stats"]
        config = info["config"]
        mode = info.get("mode", "polling")
        now = datetime.now()

        # Header
        self.console.print()
        mode_icon = "âš¡" if mode == "webhook" else "ðŸ”„"
        self.console.rule(f"[bold cyan]{proj_name}[/bold cyan] {mode_icon}", style="cyan")
        self.console.print()

        # Config info
        config_table = Table(show_header=False, box=None, padding=(0, 2))
        config_table.add_column("Key", style="cyan")
        config_table.add_column("Value")

        config_table.add_row("Project Directory", str(info["project_dir"]))
        config_table.add_row("PID", info["pid"])
        config_table.add_row("Dispatch Mode", "[green]Webhook (event-driven)[/green]" if mode == "webhook" else "[dim]Polling (legacy)[/dim]")
        config_table.add_row("Model", config.get("settings", {}).get("model", "N/A"))
        config_table.add_row("Workflow Mode", config.get("settings", {}).get("mode", "standard"))
        if mode == "polling":
            config_table.add_row("Poll Interval", f"{config.get('settings', {}).get('pollingIntervalMinutes', 1)} min")

        self.console.print(Panel(config_table, title="Configuration", border_style="blue"))
        self.console.print()

        # Runtime stats - different for webhook vs polling
        stats_table = Table(show_header=False, box=None, padding=(0, 2))
        stats_table.add_column("Metric", style="cyan")
        stats_table.add_column("Value")

        if stats.get("started_at"):
            runtime = now - stats["started_at"]
            stats_table.add_row("Runtime", self._format_duration(runtime))
            stats_table.add_row("Started", stats["started_at"].strftime("%Y-%m-%d %H:%M:%S"))
        else:
            stats_table.add_row("Runtime", "N/A")

        if mode == "webhook":
            # Webhook-specific stats
            stats_table.add_row("Events Received", str(stats.get("events_received", 0)))
            stats_table.add_row("Handlers Dispatched", str(stats.get("handlers_dispatched", 0)))

            # Show handlers by type
            handlers_by_type = stats.get("handlers_by_type", {})
            if handlers_by_type:
                breakdown = ", ".join([f"{k}: {v}" for k, v in handlers_by_type.items()])
                stats_table.add_row("Handler Breakdown", breakdown)

            # Last event
            if stats.get("last_event"):
                elapsed = (now - stats["last_event"]).total_seconds()
                if elapsed < 60:
                    last_event_str = f"{int(elapsed)}s ago"
                else:
                    last_event_str = f"{int(elapsed/60)}m ago"
                stats_table.add_row("Last Event", last_event_str)
        else:
            # Polling-specific stats
            stats_table.add_row("Current Cycle", str(stats.get("cycle", 0)))
            stats_table.add_row("Idle Count", f"{stats.get('idle_count', 0)}/{stats.get('max_idle', 12)}")
            stats_table.add_row("Workers Dispatched", str(stats.get("workers_dispatched", 0)))

            if stats.get("last_poll"):
                elapsed = (now - stats["last_poll"]).total_seconds()
                stats_table.add_row("Last Poll", f"{int(elapsed)}s ago")

        stats_table.add_row("Tasks Completed", str(stats.get("tasks_completed", 0)))

        self.console.print(Panel(stats_table, title="Runtime Statistics", border_style="green"))
        self.console.print()

        # Active workers
        if stats.get("active_workers"):
            workers_table = Table(show_header=True, box=box.ROUNDED)
            workers_table.add_column("Worker", style="cyan")
            workers_table.add_column("Task", style="white")
            workers_table.add_column("Duration", style="yellow")

            for worker in stats["active_workers"]:
                duration = now - worker["started_at"]
                workers_table.add_row(
                    worker["type"],
                    worker["task"],
                    self._format_duration(duration)
                )

            self.console.print(Panel(workers_table, title="Active Workers", border_style="yellow"))
            self.console.print()

        # Agent Health Metrics (Doctor invocations, reworks)
        metrics = info.get("metrics", {})
        if metrics:
            self._show_metrics_panel(metrics, now)

        # Log file location
        self.console.print(f"[dim]Log file: {info['log_file']}[/dim]")
        self.console.print(f"[dim]Metrics file: {info.get('metrics_file', 'N/A')}[/dim]")
        self.console.print(f"[dim]Tail logs: [cyan]joan logs {proj_name}[/cyan][/dim]\n")

    def _show_metrics_panel(self, metrics: dict, now: datetime):
        """Display agent health metrics panel with Doctor and rework details."""
        # Summary row
        summary_table = Table(show_header=False, box=None, padding=(0, 2))
        summary_table.add_column("Metric", style="cyan")
        summary_table.add_column("Value")

        doctor_count = metrics.get("doctor_invocations", 0)
        doctor_fixes = metrics.get("doctor_fixes", 0)
        rework_count = metrics.get("reworks", 0)
        completions = metrics.get("completions", 0)
        failures = metrics.get("failures", 0)

        # Health indicator based on rework/completion ratio
        if completions > 0:
            rework_ratio = rework_count / completions
            if rework_ratio < 0.1:
                health = "[green]Excellent[/green]"
            elif rework_ratio < 0.25:
                health = "[yellow]Good[/yellow]"
            elif rework_ratio < 0.5:
                health = "[yellow]Needs Attention[/yellow]"
            else:
                health = "[red]Poor[/red]"
        else:
            health = "[dim]N/A[/dim]"

        summary_table.add_row("Agent Health", health)
        summary_table.add_row("Doctor Invocations", f"{doctor_count} ({doctor_fixes} fixes applied)")
        summary_table.add_row("Rework Requests", str(rework_count))
        summary_table.add_row("Tasks Completed", str(completions))
        summary_table.add_row("Impl. Failures", str(failures) if failures else "[dim]0[/dim]")

        self.console.print(Panel(summary_table, title="ðŸ©º Agent Health Metrics", border_style="magenta"))
        self.console.print()

        # Workflow step issue distribution (if any)
        workflow_issues = metrics.get("workflow_step_issues", {})
        if workflow_issues:
            issue_table = Table(show_header=True, box=box.SIMPLE)
            issue_table.add_column("Workflow Step", style="cyan")
            issue_table.add_column("Issues", justify="right", style="yellow")

            for step, count in sorted(workflow_issues.items(), key=lambda x: -x[1]):
                issue_table.add_row(step, str(count))

            self.console.print(Panel(issue_table, title="ðŸ“ Issues by Workflow Step", border_style="blue"))
            self.console.print()

        # Recent Doctor events
        recent_doctor = metrics.get("recent_doctor_events", [])
        if recent_doctor:
            doctor_table = Table(show_header=True, box=box.SIMPLE)
            doctor_table.add_column("When", style="dim", width=12)
            doctor_table.add_column("Trigger", style="cyan", width=15)
            doctor_table.add_column("Found", justify="right", width=6)
            doctor_table.add_column("Fixed", justify="right", width=6)
            doctor_table.add_column("Issues", width=40)

            for event in reversed(recent_doctor[-5:]):  # Most recent first
                timestamp = event.get("timestamp")
                if timestamp:
                    # Handle timezone-aware datetime
                    if timestamp.tzinfo is not None:
                        timestamp = timestamp.replace(tzinfo=None)
                    elapsed = now - timestamp
                    when = self._format_duration(elapsed) + " ago"
                else:
                    when = "Unknown"

                # Summarize issues
                issues = event.get("issues", [])
                if issues:
                    issue_summary = ", ".join([
                        f"{i.get('type', 'unknown')[:20]}" for i in issues[:2]
                    ])
                    if len(issues) > 2:
                        issue_summary += f" +{len(issues)-2} more"
                else:
                    issue_summary = "-"

                doctor_table.add_row(
                    when,
                    event.get("trigger", "unknown")[:15],
                    str(event.get("issues_found", 0)),
                    str(event.get("fixes_applied", 0)),
                    issue_summary[:40]
                )

            self.console.print(Panel(doctor_table, title="ðŸ©º Recent Doctor Invocations", border_style="yellow"))
            self.console.print()

        # Recent reworks
        recent_reworks = metrics.get("recent_reworks", [])
        if recent_reworks:
            rework_table = Table(show_header=True, box=box.SIMPLE)
            rework_table.add_column("When", style="dim", width=12)
            rework_table.add_column("Task", style="cyan", width=30)
            rework_table.add_column("Step", style="yellow", width=20)
            rework_table.add_column("Reason", width=25)

            for event in reversed(recent_reworks[-5:]):  # Most recent first
                timestamp = event.get("timestamp")
                if timestamp:
                    if timestamp.tzinfo is not None:
                        timestamp = timestamp.replace(tzinfo=None)
                    elapsed = now - timestamp
                    when = self._format_duration(elapsed) + " ago"
                else:
                    when = "Unknown"

                rework_table.add_row(
                    when,
                    event.get("task_title", "Unknown")[:30],
                    event.get("workflow_step", "Reviewâ†’Dev")[:20],
                    event.get("reason", "-")[:25]
                )

            self.console.print(Panel(rework_table, title="â†©ï¸  Recent Rework Requests", border_style="red"))
            self.console.print()

    def _show_live_project_view(self, proj_name: str, info: dict):
        """Show live-updating project view (for logs command)."""
        try:
            with Live(self._generate_project_layout(proj_name, info), refresh_per_second=1, console=self.console) as live:
                while True:
                    self.discover_instances()
                    if proj_name in self.instances:
                        info = self.instances[proj_name]
                        live.update(self._generate_project_layout(proj_name, info))
                    else:
                        self.console.print("\n[yellow]Instance stopped[/yellow]\n")
                        break
                    time.sleep(1)
        except KeyboardInterrupt:
            self.console.print("\n[yellow]Stopped monitoring[/yellow]\n")

    def _generate_project_layout(self, proj_name: str, info: dict) -> Layout:
        """Generate Rich layout for live project view."""
        layout = Layout()
        layout.split_column(
            Layout(name="header", size=3),
            Layout(name="pipeline", size=9),
            Layout(name="middle", size=10),
            Layout(name="workers", size=12),
            Layout(name="logs")
        )

        # Split middle into stats and metrics side by side
        layout["middle"].split_row(
            Layout(name="stats"),
            Layout(name="metrics")
        )

        # Header
        now = datetime.now()
        header_text = Text(
            f"Joan Agents - {proj_name}  {now.strftime('%H:%M:%S')}",
            style="bold cyan",
            justify="center"
        )
        layout["header"].update(Panel(header_text, border_style="cyan"))

        stats = info["stats"]
        metrics = info.get("metrics", {})
        worker_activity = info.get("worker_activity", {})

        # Pipeline visualization
        pipeline_visual = self.generate_pipeline_visual(stats, worker_activity)
        layout["pipeline"].update(
            Panel(pipeline_visual, title="ðŸ”„ Pipeline Status", border_style="magenta")
        )

        # Stats
        stats_table = Table(show_header=False, box=None, padding=(0, 1))
        stats_table.add_column("Key", style="cyan", width=18)
        stats_table.add_column("Value")

        stats_table.add_row("Cycle", str(stats.get("cycle", 0)))
        stats_table.add_row("Idle", f"{stats.get('idle_count', 0)}/{stats.get('max_idle', 12)}")
        stats_table.add_row("Tasks Completed", str(stats.get("tasks_completed", 0)))
        stats_table.add_row("Workers Dispatched", str(stats.get("workers_dispatched", 0)))

        if stats.get("last_poll"):
            elapsed = (now - stats["last_poll"]).total_seconds()
            stats_table.add_row("Last Poll", f"{int(elapsed)}s ago")

        layout["stats"].update(Panel(stats_table, title="Stats", border_style="green"))

        # Metrics panel (Agent Health)
        metrics_table = Table(show_header=False, box=None, padding=(0, 1))
        metrics_table.add_column("Metric", style="cyan", width=18)
        metrics_table.add_column("Value")

        doctor_count = metrics.get("doctor_invocations", 0)
        doctor_fixes = metrics.get("doctor_fixes", 0)
        rework_count = metrics.get("reworks", 0)
        completions = metrics.get("completions", 0)
        failures = metrics.get("failures", 0)

        # Health color
        if completions > 0:
            rework_ratio = rework_count / completions
            if rework_ratio < 0.1:
                health = "[green]Excellent[/green]"
            elif rework_ratio < 0.25:
                health = "[yellow]Good[/yellow]"
            else:
                health = "[red]Needs Attention[/red]"
        else:
            health = "[dim]N/A[/dim]"

        metrics_table.add_row("Health", health)
        doctor_style = "red" if doctor_count >= 5 else "yellow" if doctor_count >= 2 else "white"
        metrics_table.add_row("ðŸ©º Doctor", f"[{doctor_style}]{doctor_count}[/{doctor_style}] ({doctor_fixes} fixes)")
        rework_style = "red" if rework_count >= 5 else "yellow" if rework_count >= 2 else "white"
        metrics_table.add_row("â†©ï¸  Reworks", f"[{rework_style}]{rework_count}[/{rework_style}]")
        metrics_table.add_row("âŒ Failures", f"[red]{failures}[/red]" if failures else "[dim]0[/dim]")

        layout["metrics"].update(Panel(metrics_table, title="Agent Health", border_style="magenta"))

        # Workers - combine scheduler log detection + worker activity log
        workers_content = Text()
        has_worker_info = False

        # Show current worker from worker-activity.log (most reliable)
        if worker_activity.get("current_worker") and worker_activity.get("current_status") == "WORKING":
            has_worker_info = True
            worker_type = worker_activity["current_worker"]
            task = worker_activity.get("current_task", "Unknown task")[:40]
            last_msg = worker_activity.get("last_message", "")[:50]

            if worker_activity.get("last_update"):
                elapsed = now - worker_activity["last_update"]
                elapsed_str = self._format_duration(elapsed)
            else:
                elapsed_str = "--:--"

            workers_content.append(f"ðŸ”„ {worker_type}", "bold green")
            workers_content.append(f"  {task}\n", "white")
            if last_msg and last_msg != task:
                workers_content.append(f"   â””â”€ {last_msg}", "dim cyan")
                workers_content.append(f" ({elapsed_str} ago)\n", "dim")

            # Recent worker events
            recent_events = worker_activity.get("recent_events", [])[-5:]
            if recent_events:
                workers_content.append("\nRecent Activity:\n", "dim")
                for event in reversed(recent_events):
                    evt_elapsed = now - event["timestamp"]
                    evt_time = self._format_duration(evt_elapsed)
                    status_icon = {"START": "â–¶", "PROGRESS": "â—†", "COMPLETE": "âœ“", "FAIL": "âœ—"}.get(event["status"], "â€¢")
                    status_style = {"START": "green", "PROGRESS": "cyan", "COMPLETE": "green", "FAIL": "red"}.get(event["status"], "white")
                    workers_content.append(f"  {evt_time:>8} ", "dim")
                    workers_content.append(f"{status_icon} ", status_style)
                    workers_content.append(f"[{event['worker']}] ", "cyan")
                    workers_content.append(f"{event['message'][:35]}\n", "white")

        # Fallback: show from scheduler log if no worker activity
        elif stats.get("active_workers"):
            has_worker_info = True
            for worker in stats["active_workers"]:
                duration = now - worker["started_at"]
                workers_content.append(f"ðŸ”„ {worker['type']}", "bold yellow")
                workers_content.append(f"  {worker['task'][:40]}", "white")
                workers_content.append(f"  ({self._format_duration(duration)})\n", "dim")
            workers_content.append("\n[dim]Note: No worker-activity.log - showing scheduler log data[/dim]", "dim")

        if has_worker_info:
            layout["workers"].update(Panel(workers_content, title="Active Workers", border_style="yellow"))
        else:
            layout["workers"].update(Panel("No active workers", title="Active Workers", border_style="dim"))

        # Bottom panel: Worker Progress (when active) or Recent Logs (when idle)
        # Determine if a worker is actively running
        active_worker_type = None
        if worker_activity.get("current_worker") and worker_activity.get("current_status") == "WORKING":
            active_worker_type = worker_activity["current_worker"]
        elif stats.get("active_workers"):
            # Fallback to scheduler-detected workers
            for w in stats["active_workers"]:
                if w.get("type") in ["BA", "Architect", "Dev", "Reviewer", "Ops"]:
                    active_worker_type = w["type"]
                    break

        if active_worker_type and info.get("worker_log"):
            # Show Worker Progress view - focused on the active worker
            progress_content = self._get_worker_progress_content(
                info["worker_log"],
                worker_type=active_worker_type,
                max_lines=15
            )
            title = f"ðŸ“‹ {active_worker_type} Worker Progress"
            layout["logs"].update(Panel(progress_content, title=title, border_style="green"))
        else:
            # No active worker - show Recent Logs from scheduler
            if info["log_file"].exists():
                try:
                    with open(info["log_file"], 'r') as f:
                        lines = f.readlines()
                    recent = "".join(lines[-15:])
                    layout["logs"].update(Panel(Text(recent, style="dim"), title="Recent Logs", border_style="blue"))
                except:
                    layout["logs"].update(Panel("Error reading logs", border_style="red"))
            else:
                layout["logs"].update(Panel("No logs available", title="Recent Logs", border_style="dim"))

        return layout

    def tail_logs(self, project_name: str):
        """Tail logs for a specific project."""
        self.discover_instances()

        matches = [
            (name, info) for name, info in self.instances.items()
            if project_name.lower() in name.lower()
        ]

        if not matches:
            self.console.print(f"\n[red]No running instance found for '{project_name}'[/red]\n")
            return

        if len(matches) > 1:
            self.console.print(f"\n[yellow]Multiple matches found:[/yellow]")
            for name, _ in matches:
                self.console.print(f"  - {name}")
            self.console.print("\n[dim]Be more specific[/dim]\n")
            return

        proj_name, info = matches[0]
        log_file = info["log_file"]

        if not log_file.exists():
            self.console.print(f"\n[red]Log file not found: {log_file}[/red]\n")
            return

        self.console.print(f"\n[cyan]Tailing logs for {proj_name}[/cyan]")
        self.console.print(f"[dim]{log_file}[/dim]\n")
        self.console.print("[dim]Press Ctrl+C to stop[/dim]\n")

        try:
            subprocess.run(["tail", "-f", str(log_file)])
        except KeyboardInterrupt:
            self.console.print("\n[yellow]Stopped tailing logs[/yellow]\n")

    def generate_pipeline_visual(self, stats: dict, worker_activity: dict = None) -> Text:
        """Generate the pipeline visualization with blinking active stage."""
        text = Text()
        worker_activity = worker_activity or {}

        # Toggle blink state for animation
        self.blink_state = not self.blink_state

        # Find active stage - prefer worker_activity.log (more reliable)
        active_stage = None
        active_task = None
        last_progress = None
        doctor_active = False
        waiting_stages = {}  # Stages with tasks waiting (not actively being worked)

        # Primary source: worker-activity.log
        if worker_activity.get("current_worker") and worker_activity.get("current_status") == "WORKING":
            worker_type = worker_activity["current_worker"]
            stage_map = {"BA": "BA", "Architect": "Architect", "Dev": "Dev",
                        "Reviewer": "Reviewer", "Ops": "Ops"}
            if worker_type in stage_map:
                active_stage = stage_map[worker_type]
                active_task = worker_activity.get("current_task", "")
                last_progress = worker_activity.get("last_message", "")

        # Fallback: scheduler log parsing
        if not active_stage:
            for worker in stats.get("active_workers", []):
                worker_type = worker.get("type", "")
                # Map worker types to pipeline stages
                stage_map = {"BA": "BA", "Architect": "Architect", "Dev": "Dev",
                            "Reviewer": "Reviewer", "Ops": "Ops", "Doctor": None}
                if worker_type == "Doctor":
                    doctor_active = True
                elif worker_type in stage_map and stage_map[worker_type]:
                    active_stage = stage_map[worker_type]
                    active_task = worker.get("task", "")

        # If no active workers, check pipeline_state for waiting tasks
        pipeline_state = stats.get("pipeline_state", {})
        if not active_stage and pipeline_state:
            waiting_stages = pipeline_state
            # Find the furthest stage with waiting tasks (prioritize later stages)
            for stage in reversed(self.PIPELINE_STAGES):
                if stage in pipeline_state and pipeline_state[stage] > 0:
                    active_stage = stage
                    active_task = f"{pipeline_state[stage]} task(s) waiting"
                    break

        # Build pipeline visualization
        stages_display = []
        has_active_worker = any(w.get("type") in ["BA", "Architect", "Dev", "Reviewer", "Ops"]
                                for w in stats.get("active_workers", []))

        for stage in self.PIPELINE_STAGES:
            is_active = (stage == active_stage)
            has_waiting = stage in waiting_stages and waiting_stages[stage] > 0

            if is_active and has_active_worker:
                # Actively working - blinking green
                if self.blink_state:
                    style = "bold bright_green on green"
                    icon = "â—"
                else:
                    style = "bold green"
                    icon = "â—‹"
            elif is_active or has_waiting:
                # Waiting/queued - steady yellow
                style = "bold yellow"
                icon = "â—"  # Half-filled to indicate waiting
            else:
                style = "dim white"
                icon = "â—‹"

            stages_display.append((stage, style, icon, is_active or has_waiting))

        # Top border
        text.append("  ")
        for i, (stage, style, icon, is_active) in enumerate(stages_display):
            width = max(len(stage) + 2, 8)
            text.append("â”Œ" + "â”€" * width + "â”", style if is_active else "dim")
            if i < len(stages_display) - 1:
                text.append("    ", "dim")
        text.append("\n")

        # Stage names with icons
        text.append("  ")
        for i, (stage, style, icon, is_active) in enumerate(stages_display):
            width = max(len(stage) + 2, 8)
            content = f"{icon} {stage}"
            padding = width - len(content)
            left_pad = padding // 2
            right_pad = padding - left_pad
            text.append("â”‚" + " " * left_pad + content + " " * right_pad + "â”‚", style)
            if i < len(stages_display) - 1:
                text.append("â”€â”€â”€â–º", "cyan" if is_active else "dim")
        text.append("\n")

        # Bottom border
        text.append("  ")
        for i, (stage, style, icon, is_active) in enumerate(stages_display):
            width = max(len(stage) + 2, 8)
            text.append("â””" + "â”€" * width + "â”˜", style if is_active else "dim")
            if i < len(stages_display) - 1:
                text.append("    ", "dim")
        text.append("\n")

        # Current task indicator
        # Check if there's an active worker from either source
        is_actively_working = has_active_worker or (
            worker_activity.get("current_worker") and
            worker_activity.get("current_status") == "WORKING"
        )

        if active_stage and active_task:
            text.append("\n  ")
            task_display = active_task[:50] + "..." if len(active_task) > 50 else active_task
            if is_actively_working:
                text.append(f"  â–¶ {active_stage}: ", "bold green")
                text.append(task_display, "white")
                # Show last progress message if available
                if last_progress and last_progress != active_task:
                    progress_display = last_progress[:60] + "..." if len(last_progress) > 60 else last_progress
                    text.append("\n     ")
                    text.append(f"â””â”€ {progress_display}", "dim cyan")
                # Show elapsed time if available
                if worker_activity.get("last_update"):
                    elapsed = datetime.now() - worker_activity["last_update"]
                    elapsed_str = self._format_duration(elapsed)
                    text.append(f" ({elapsed_str})", "dim")
            else:
                text.append(f"  â— {active_stage}: ", "bold yellow")
                text.append(task_display, "dim white")

        # Doctor indicator (separate, blinking red when active)
        if doctor_active:
            text.append("\n\n  ")
            if self.blink_state:
                text.append("  ðŸ¥ DOCTOR ", "bold bright_red on red")
            else:
                text.append("  ðŸ¥ DOCTOR ", "bold red")
            text.append(" Diagnosing issues...", "red")

        return text

    def _format_duration(self, duration: timedelta) -> str:
        """Format duration as HH:MM:SS or MM:SS."""
        total_seconds = int(duration.total_seconds())
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60

        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
        else:
            return f"{minutes:02d}:{seconds:02d}"


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Joan Agents - Global monitoring and management",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "command",
        choices=["status", "logs"],
        help="Command to run"
    )

    parser.add_argument(
        "project",
        nargs="?",
        help="Project name (partial match supported)"
    )

    parser.add_argument(
        "-f", "--follow",
        action="store_true",
        help="Follow/live update (for status command)"
    )

    args = parser.parse_args()

    monitor = JoanMonitor()

    if args.command == "status":
        if args.project:
            monitor.show_project_view(args.project, follow=args.follow)
        else:
            monitor.show_global_view(live_mode=args.follow)
    elif args.command == "logs":
        if not args.project:
            print("Error: Project name required for logs command")
            sys.exit(1)
        monitor.tail_logs(args.project)


if __name__ == "__main__":
    main()
